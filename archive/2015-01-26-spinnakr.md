---
layout: post
title:  "Spinnakr"
categories: go
---

* *The following post outlines some of the work I did while working at Spinnakr*

For the past year I have been working on Golang projects that interact with Redis, Etcd, and Nsq.  In addition to using these projects in our software, I have been writing about the details of how they work internally.  We are in the very early stages of developing software infrastructure that makes it easier to run distributed applications.

One of the harder problems in distributed computing is the ability to have multiple processes come to consensus on a state machine.  Etcd is attempting to solve this problem via a new algorithm called Raft that was developed by Diego Ongaro, a PhD student at Stanford in August 2014.

The basis of this work is driving development of future operating systems that live in the cloud and act in the context of app container specifications like Docker and Rocket.

For the past three years, I have been working at Spinnakr along with two other team members on a big data analytics platform.  The system monitors 1000+ customers who receive 1,000,000+ events per day on their collective websites.

At the heart of the system is RabbitMq and Redis.  Redis enables ultra fast storage and retrieval of information because all of its data structures sit in memory.  Disk access is only used to make snapshots of the data over time as things change.  Rabbit receives all of the events and then multiple redis instances subscribe to the channels. This data is then processed and REST Apis are used for disbursement of the information to customer dashboards which have the ability to subscribe to these feeds and do further data processing on this information.

The next evolutionary step of the system is the ability to search across the entire space of data using an open source search architecture based on Lucene called ElasticSearch.  Since all of the data structures are already in JSON this makes the migration to elasticsearch trivial.

In the past, I have worked on front end visualization of this analytics data using Backbone, D3, and AngularJS, but for now I am focusing all of my attention on the backend services mentioned above.

On Amazon we have about 20 instances running, 10 of which run different
large Redis instances that are all constantly subscribing to messages, generating redis data structures, as well as handling requests which generate out JSON. The Redis instances are robust in that they have been running for months with no down time.
